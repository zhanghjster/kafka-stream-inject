### 架构

kafka stream通过kafka生产者消费者库以及本身提供的数据并行、分布式协作、并行性以及操作简单性来简化应用开发

<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-overview.jpg" width="400">

上图是一个典型的kafka stream程序的逻辑视图，它包含了多个流处理线程，每个线程包含了多个流处理任务

### 处理器拓扑

处理器拓扑定义了应用程序的流处理计算逻辑，即输入数据是如何转化为输出数据。拓扑由多个流（边）链接流处理器（结点）组成的图形。其中有两个特殊的流处理器：

* 源处理器：它没有上游处理器，通过消费kafka topic将记录转发到下游处理器为拓扑结构的生成输入流
* 汇处理器：他没有下游处理器，将上游处理机的记录转发到指定的kafka主题

流处理程序可以定义一个或多个拓扑，但一般定义一个。开发人员可以通过底层的处理器API或者Kafka Stream DSL定义拓扑结构，下图展示了一个处理器拓扑的基本结构和元素

<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-topology.jpg" width="400">



处理器拓扑仅仅是流处理代码的逻辑抽象。在运行时，拓扑要被实例化并在程序内部并行处理。

### 并行模型

#### 流分区和任务

Kafka Stream使用分区和任务作为并行模型的逻辑单元。在并行背景下kafka stream和kafka有紧密联系

* 每个流分区是完全有序的数据记录，并映射到kafka主题分区
* 流中的数据记录映射到该分区的kafka消息
* 数据记录中的关键字决定了kafka和kafka stream中数据的分区，即数据如何路由到主题的特定分区

Kafka Stream根据应用程序的输入流分区创建固定数量的任务，每个任务都分配了来自输入流（即Kafka主题）的分区列表。分区对任务的分配不会改变，因此每个任务都是应用程序的固定并行单元，可以理解为实例化的处理器拓扑。任务然后可以基于所分配的分区实例化它们自己的处理器拓扑;它们还为每个分配的分区保留一个缓冲区，并从这些记录缓冲区中一次一个地处理消息。下图描述了分区和任务之间的关系, 一个分区只能对应一个任务，但一个任务可以处理多个分区。

<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-tasks.jpg" width="400">

值得注意的是，kafka Stream不是一个资源管理器，他是指在流处理程序运行使用的库。应用程序的多个实例可以在同一台机器上执行，也可以分布在多台机器上，任务由库自动分配给正在运行的应用实例，分配的任务不会进行改变直到程序运行失败，进而任务会分配到其他实力上重新启动

#### 线程模型

Kafka Streams允许用户配置库可用于在应用程序实例中并行处理的线程数。每个线程都可以独立执行一个或多个具有处理器拓扑的任务, 如下图所示

<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-threads.jpg" width="400">

启动更多流线程或应用程序实例仅仅意味着复制拓扑并使其处理不同的Kafka分区子集，从而有效地并行处理。值得注意的是，线程之间没有共享状态，所以不需要线程间协调。这使得跨应用程序实例和线程并行运行拓扑非常简单。 Kafka Streams利用Kafka的服务器端协调功能透明地处理各种流线程之间的Kafka主题分区

所以，使用Kafka Streams扩展流处理应用程序非常简单：只需启动应用程序的其他实例，而Kafka Streams负责在应用程序实例中运行的任务之间分配分区。可以启动与输入Kafka主题分区相同数量的应用程序线程，以便在应用程序的所有正在运行的实例中，每个线程（或者说它运行的任务）至少有一个输入分区来处理

### 例子

Kafka Streams应用程序消耗了两个主题A和B，每个主题都有3个分区。如果我们现在在配置为2的线程数的单台机器上启动应用程序，那么最终会有两个流线程instance1-thread1和instance1-thread2。由于输入主题A和B的最大分区数量为max（3，3）== 3，因此Kafka Streams默认将此拓扑分为三个任务，然后在这三个任务中均匀分配六个输入主题分区;在这种情况下，每个任务将从每个输入主题的一个分区消耗，每个任务总共有两个输入分区。最后，这三个任务将在两个可用线程之间均匀分布 - 在可能的范围内 - 在此示例中，这意味着第一个线程将运行2个任务（从4个分区中消耗），第二个线程将运行1个任务（消耗2个分区）。下图描述了线程、任务、分区之间的关系

<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-example-01.png" width="400">

现在想象一下，随着数据量的增大，我们需要拓展此应用程序，在另一台不同的机器上运行相同的程序。一个新的线程instance2-thread1将被创建，并且输入分区将被重新分配，如下图所示

<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-example-02.png" width="400">

发生重新分配时，某些分区（包括任何本地状态存储的相应任务）将从现有线程“迁移”到新添加的线程。这里是从第一台机器上的instance1-thread1到instance2-thread1在第二台机器上）。因此，Kafka Streams以kafka topic分区的粒度有效地重新平衡了应用程序实例之间的工作负载

如果想要添加更多相同应用程序的实例呢？这样做是可以的，直到某个点，即正在运行的实例数等于要读取的可用输入分区数时。此时，在运行更多应用程序实例之前，我们首先需要增加主题A和B的分区数;否则，我们会过度配置应用程序，最终导致等待分配给它们的空闲实例

### 状态

Kafka Streams提供了状态存储，流处理应用程序可以使用它来存储和查询数据，这是实现有状态操作的重要功能。 Kafka Streams中的每个任务都嵌入了一个或多个可通过API访问的状态存储，用以存储和查询处理所需的数据。这些状态存储可以是RocksDB数据库，内存中的哈希映射或其他方便的数据结构。 Kafka Streams为本地存储提供容错和自动恢复功能。

Kafka Streams确保本地存储有效的容错。它遵循与Apache Samza类似的方法，为每个本地存储维护一个复制的更改日志，日志会存储到Kafka主题用以跟踪任何状态更新。这些更改日志主题也进行了分区，以便每个本地状态存储实例以及因此访问存储的任务都有其自己的专用更改日志主题分区。在更改日志主题上启用日志压缩，以便可以安全地清除旧数据，以防止主题无限增长。如果任务在一台计算机上运行失败后在另一台计算机上重新启动，则Kafka Streams保证在恢复对新启动的任务的处理之前，通过重播相应的更改日志主题，将其关联的状态存储恢复到故障发生前的内容。因此，故障处理对最终用户来说是完全透明的。