Kafka Streams是一个客户端库，用于分析和处理存储在Kafka中的数据。它基于一些重要的流处理概念，如正确区分事件时间和处理时间，支持窗口以及有效管理和实时查询应用程序状态。

kafka stream入门很容易，可以很快上手写一个单机运行的概念验证程序，也可以在多台机器上运行程序多个实例来实现扩展以应付生产环境的负载增长，kafka stream透明的处理应用程序多个实例间的负载均衡。

下面是kafka stream几个比较突出的特点：

* 设计为简单轻量的客户端库，可以轻松的嵌入到任何Java程序中
* 除了Kafka本身作为内部消息传递层之外，没有外部依赖
* 通过kafka的分区模型还实现横向扩展，并且保证数据的有序性
* 支持本地状态容错，可以实现快速高效的有状态操作，如窗口链接和聚合
* 支持一次处理语义，即使在处理过程中出现Streams客户端或Kafka代理失败时，每条记录也只会被处理一次
* 采用一次一笔记录处理，实现毫秒级处理延迟
* 支持基于事件时间的窗口操作并支持对延迟到达记录的处理
* 提供必要的流处理原语，包括高级Streams DSL和底层的Processor API

### 时间

流处理中有个关键概念就是“时间”以及它如何建模和整合，下面是流处理中常见的“时间”概念：

* 事件时间：事件或数据记录产生的时间，比如一个GSP传感器记录地理位置所用的时间就是它捕获位置的时间
* 摄取时间：由kafka broker生成的将事件记录到主题分区时间点
* 处理时间：流处理程序处理事件或数据的时间点，可能会比事件时间晚数毫秒、小时、甚至数天。

事件时间和摄取时间之间的选择是通过配置Kafka（而非Kafka Streams）完成的：从Kafka 0.10.x开始，时间戳会自动嵌入到Kafka消息中。根据Kafka的配置，这些时间戳代表事件时间或摄取时间。可以在broker级别或topic级别上指定相应的Kafka配置设置。 Kafka Streams中的默认时间戳提取器将按原样检索这些嵌入的时间戳。因此，应用程序的有效时间定义取决于这些嵌入式时间戳的有效Kafka配置。

Kafka Streams通过TimestampExtractor接口为每个数据记录分配一个时间戳。这些时间戳记描述了流的时间方面的进度，并由时间相关的操作（例如窗口操作）使用。这个‘时间‘只会在新记录到达处理器时才会推进。我们将这个数据驱动时间称为应用程序的流时间，以便在应用程序实际执行时与挂钟时间区分开来。 TimestampExtractor接口的具体实现将为流时间定义提供不同的语义。例如基于数据记录的实际内容（诸如嵌入时间戳字段）来检索或计算时间戳以提供事件时间语义，并且返回当前挂钟时间，从而产生处理时间语义以产生时间流。开发人员可以根据业务需求实施不同的时间概念。

最后，无论何时Kafka Streams应用程序向Kafka写入记录，它都会为这些新记录分配时间戳。时间戳的分配方式取决于上下文

* 当通过处理某些输入记录生成新输出记录时，例如，在process（）函数调用中触发context.forward（）时，输出记录时间戳直接从输入记录时间戳
* 当通过周期性函数（如Punctuator＃punctuate（））生成新的输出记录时，输出记录时间戳被定义为流任务的当前内部时间（通过context.timestamp（）获取）
* 对于聚合，生成的聚合更新记录的时间戳将是触发更新的最新到达的输入记录的时间戳

### 状态

Kafka Streams提供了状态存储，流处理应用程序可以使用它来存储和查询数据，这是实现有状态操作的重要功能。 Kafka Streams中的每个任务都嵌入了一个或多个可通过API访问的状态存储，用以存储和查询处理所需的数据。这些状态存储可以是RocksDB数据库，内存中的哈希映射或其他方便的数据结构。 Kafka Streams为本地存储提供容错和自动恢复功能。

Kafka Streams确保本地存储有效的容错。它遵循与Apache Samza类似的方法，为每个本地存储维护一个复制的更改日志，日志会存储到Kafka主题用以跟踪任何状态更新。这些更改日志主题也进行了分区，以便每个本地状态存储实例以及因此访问存储的任务都有其自己的专用更改日志主题分区。在更改日志主题上启用日志压缩，以便可以安全地清除旧数据，以防止主题无限增长。如果任务在一台计算机上运行失败后在另一台计算机上重新启动，则Kafka Streams保证在恢复对新启动的任务的处理之前，通过重播相应的更改日志主题，将其关联的状态存储恢复到故障发生前的内容。因此，故障处理对最终用户来说是完全透明的。

### 架构

kafka stream通过kafka生产者消费者库以及本身提供的数据并行、分布式协作、并行性以及操作简单性来简化应用开发

<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-overview.jpg" width="400">

上图是一个典型的kafka stream程序的逻辑视图，它包含了多个流处理线程，每个线程包含了多个流处理任务

### 处理器拓扑

处理器拓扑定义了应用程序的流处理计算逻辑，即输入数据是如何转化为输出数据。拓扑由多个流（边）链接流处理器（结点）组成的图形。其中有两个特殊的流处理器：

* 源处理器：它没有上游处理器，通过消费kafka topic将记录转发到下游处理器为拓扑结构的生成输入流
* 汇处理器：他没有下游处理器，将上游处理机的记录转发到指定的kafka主题

流处理程序可以定义一个或多个拓扑，但一般定义一个。开发人员可以通过底层的Processor API或者Stream DSL定义拓扑结构。Kafka Streams DSL提供了一些开箱即用的常见数据转换操作，例如map、filter、aggregate、join，而Processor API可以让开发者定制处理器及与状态存储交互。



<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-topology.jpg" width="400">



上图展示了一个处理器拓扑的基本结构和元素，处理器拓扑仅仅是流处理代码的逻辑抽象。在运行时，拓扑要被实例化并在程序内部并行处理。

### 并行模型

#### 流分区和任务

Kafka Stream使用分区和任务作为并行模型的逻辑单元。在并行背景下kafka stream和kafka有紧密联系

* 每个流分区是完全有序的数据记录，并映射到kafka主题分区
* 流中的数据记录映射到该分区的kafka消息
* 数据记录中的关键字决定了kafka和kafka stream中数据的分区，即数据如何路由到主题的特定分区

Kafka Stream根据应用程序的输入流分区创建固定数量的任务，每个任务都分配了来自输入流（即Kafka主题）的分区列表。分区对任务的分配不会改变，因此每个任务都是应用程序的固定并行单元，可以理解为实例化的处理器拓扑。任务然后可以基于所分配的分区实例化它们自己的处理器拓扑;它们还为每个分配的分区保留一个缓冲区，并从这些记录缓冲区中一次一个地处理消息。下图描述了分区和任务之间的关系, 一个分区只能对应一个任务，但一个任务可以处理多个分区。

<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-tasks.jpg" width="400">

值得注意的是，kafka Stream不是一个资源管理器，他是指在流处理程序运行使用的库。应用程序的多个实例可以在同一台机器上执行，也可以分布在多台机器上，任务由库自动分配给正在运行的应用实例，分配的任务不会进行改变直到程序运行失败，进而任务会分配到其他实力上重新启动

#### 线程模型

Kafka Streams允许用户配置库可用于在应用程序实例中并行处理的线程数。每个线程都可以独立执行一个或多个具有处理器拓扑的任务, 如下图所示

<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-threads.jpg" width="400">

启动更多流线程或应用程序实例仅仅意味着复制拓扑并使其处理不同的Kafka分区子集，从而有效地并行处理。值得注意的是，线程之间没有共享状态，所以不需要线程间协调。这使得跨应用程序实例和线程并行运行拓扑非常简单。 Kafka Streams利用Kafka的服务器端协调功能透明地处理各种流线程之间的Kafka主题分区

所以，使用Kafka Streams扩展流处理应用程序非常简单：只需启动应用程序的其他实例，而Kafka Streams负责在应用程序实例中运行的任务之间分配分区。可以启动与输入Kafka主题分区相同数量的应用程序线程，以便在应用程序的所有正在运行的实例中，每个线程（或者说它运行的任务）至少有一个输入分区来处理

### 例子

Kafka Streams应用程序消耗了两个主题A和B，每个主题都有3个分区。如果我们现在在配置为2的线程数的单台机器上启动应用程序，那么最终会有两个流线程instance1-thread1和instance1-thread2。由于输入主题A和B的最大分区数量为max（3，3）== 3，因此Kafka Streams默认将此拓扑分为三个任务，然后在这三个任务中均匀分配六个输入主题分区;在这种情况下，每个任务将从每个输入主题的一个分区消耗，每个任务总共有两个输入分区。最后，这三个任务将在两个可用线程之间均匀分布 - 在可能的范围内 - 在此示例中，这意味着第一个线程将运行2个任务（从4个分区中消耗），第二个线程将运行1个任务（消耗2个分区）。下图描述了线程、任务、分区之间的关系

<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-example-01.png" width="400">

现在想象一下，随着数据量的增大，我们需要拓展此应用程序，在另一台不同的机器上运行相同的程序。一个新的线程instance2-thread1将被创建，并且输入分区将被重新分配，如下图所示

<img src="https://docs.confluent.io/3.0.0/_images/streams-architecture-example-02.png" width="400">

发生重新分配时，某些分区（包括任何本地状态存储的相应任务）将从现有线程“迁移”到新添加的线程。这里是从第一台机器上的instance1-thread1到instance2-thread1在第二台机器上）。因此，Kafka Streams以kafka topic分区的粒度有效地重新平衡了应用程序实例之间的工作负载

如果想要添加更多相同应用程序的实例呢？这样做是可以的，直到某个点，即正在运行的实例数等于要读取的可用输入分区数时。此时，在运行更多应用程序实例之前，我们首先需要增加主题A和B的分区数;否则，我们会过度配置应用程序，最终导致等待分配给它们的空闲实例

